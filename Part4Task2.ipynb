{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords and stemmer\n",
    "stop_words = set(stopwords.words(\"english\"))                        # load English stopwords from NLTK\n",
    "stemmer = PorterStemmer()                                           # create a new Porter stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text preprocessing functions\n",
    "def clean_text(text):\n",
    "    text = text.lower()                                             # convert to lowercase\n",
    "    spaces = re.compile(r'\\s+')\n",
    "    text = spaces.sub(' ', text)                                    # substitute all white space characters (single or multiple occurences) with a single space\n",
    "\n",
    "    emails = re.compile(r'\\S+@\\S+\\.\\S+')\n",
    "    text = emails.sub('_EMAIL_', text)                              # substitute all found email addresses with _EMAIL_\n",
    "    urls = re.compile(r'http[s]?:\\/\\/\\S+|www\\.\\S+|\\S+\\.[a-z]+\\/\\S+|\\w+\\.(?:com|net|org)')\n",
    "    text = urls.sub('_URL_', text)                                  # substitute all found URLs with _URL_\n",
    "    dates = re.compile(r'''\n",
    "                       \\d{1,4}[-\\/]\\d{1,2}[-\\/]\\d{1,4}|\n",
    "                       \\d{1,2}\\ (?:jan[a-z]*|feb[a-z]*|mar[a-z]*|apr[a-z]*|may|jun[e]?|jul[y]?|aug[a-z]*|sep[a-z]*|oct[a-z]*|nov[a-z]*|dec[a-z]*)\\ \\d{,4}|\n",
    "                       (?:jan[a-z]*|feb[a-z]*|mar[a-z]*|apr[a-z]*|may|jun[e]?|jul[y]?|aug[a-z]*|sep[a-z]*|oct[a-z]*|nov[a-z]*|dec[a-z]*)[,.]?\\ ?\\d{1,4}(?:th|st|nd|rd)?(?:,\\ \\d{4})?\n",
    "                       ''', re.VERBOSE)\n",
    "    text = dates.sub('_DATE_', text)                                # substitute all found dates with _DATE_\n",
    "    numbers = re.compile(r'\\d+(?:th|st|nd|rd)?')\n",
    "    text = numbers.sub('_NUM_', text)                               # substitute all remaining numbers with _NUM_\n",
    "    return text\n",
    "\n",
    "def remove_stopwords_and_stem(tokens):\n",
    "    return [stemmer.stem(word) for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on Liar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "liar_test = \"test.tsv\"\n",
    "liar_processed = \"liar_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "0    [build, wall, u.s.-mexico, border, take, liter...\n",
      "1    [wisconsin, pace, doubl, number, layoff, year, .]\n",
      "Name: stemmed_tokens, dtype: object\n",
      "<class 'str'>\n",
      "0    build wall u.s.-mexico border take liter year .\n",
      "1          wisconsin pace doubl number layoff year .\n",
      "Name: stemmed_tokens, dtype: object\n",
      "label\n",
      "half-true      265\n",
      "false          249\n",
      "mostly-true    241\n",
      "barely-true    212\n",
      "true           208\n",
      "pants-fire      92\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "0    449\n",
      "1    341\n",
      "Name: count, dtype: int64\n",
      "Processing complete! Data saved to: liar_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Read and process test data from the LIAR dataset\n",
    "liar_df = pd.read_csv(liar_test, sep = '\\t', usecols=[1,2], names=['label', 'statement'])\n",
    "\n",
    "# Apply text preprocessing pipeline\n",
    "liar_df['statement'] = liar_df['statement'].apply(clean_text)                                   # cleaning the statements in the statement column\n",
    "liar_df['statement'] = liar_df['statement'].apply(word_tokenize)                                # tokenizing the statements in the statement column\n",
    "liar_df['stemmed_tokens'] = liar_df['statement'].apply(remove_stopwords_and_stem)               # removing stopwords and stemming the tokens \n",
    "\n",
    "# Convert data in 'stemmed_tokens' column from list of strings\n",
    "# to a single string pr. article (as this is what e.g. CountVectorizer expects as input)\n",
    "print(type(liar_df['stemmed_tokens'][0]))\n",
    "print(liar_df['stemmed_tokens'].head(2))\n",
    "liar_df['stemmed_tokens'] = liar_df['stemmed_tokens'].apply(lambda x: ' '.join(x))\n",
    "print(type(liar_df['stemmed_tokens'][0]))\n",
    "print(liar_df['stemmed_tokens'].head(2))\n",
    "\n",
    "\n",
    "# Print overview of occuring labels \n",
    "print(liar_df['label'].value_counts())\n",
    "\n",
    "fake_lables = ['pants-fire', 'false']\n",
    "reliable_lables = ['true', 'mostly-true']\n",
    "\n",
    "liar_df = liar_df[liar_df['label'].isin(fake_lables + reliable_lables)]                     # Keep only relevant labels\n",
    "liar_df['label'] = liar_df['label'].apply(lambda x: 1 if x in fake_lables else 0)             # Convert the 'label' column to numerical values\n",
    "\n",
    "print(liar_df['label'].value_counts())                                                      # Print the count of statements grouped as 'fake' or 'reliable'\n",
    "\n",
    "\n",
    "# Write and save processed data to csv file\n",
    "liar_df.to_csv(liar_processed, columns=['stemmed_tokens', 'label'], mode=\"w\", index=False, header=True)\n",
    "\n",
    "print(\"Processing complete! Data saved to:\", liar_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model on the LIAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 10\n",
      "min_resources_: 20\n",
      "max_resources_: 599891\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 160\n",
      "n_resources: 20\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 160 is smaller than n_iter=29994. Running 160 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "400 fits failed out of a total of 800.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "79 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "78 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "243 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56666667 0.55              nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.51666667\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.48333333        nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.68333333        nan        nan\n",
      " 0.56666667 0.68333333        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.63333333        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.61666667        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.     0.545     nan    nan 1.     0.6325    nan    nan 1.     0.48\n",
      "    nan    nan 1.     0.52      nan    nan 1.     0.53      nan    nan\n",
      " 1.     0.48      nan    nan 1.     0.5075    nan    nan 1.     0.5825\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan\n",
      " 1.     1.        nan    nan 1.     1.        nan    nan 1.     1.\n",
      "    nan    nan 1.     1.        nan    nan 1.     1.        nan    nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 60\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56666667 0.55              nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.51666667\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.48333333        nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.68333333        nan        nan\n",
      " 0.56666667 0.68333333        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.63333333        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.61666667        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.58939394 0.58787879\n",
      " 0.58939394 0.55151515 0.58787879 0.55151515 0.55151515 0.58939394\n",
      " 0.58787879 0.55151515 0.60757576 0.58939394 0.56969697 0.55151515\n",
      " 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.56969697 0.56969697 0.55151515 0.55151515 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.55151515 0.56969697 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.60606061 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.60757576 0.58939394 0.60757576 0.60757576]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         0.545             nan        nan 1.         0.6325\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.52              nan        nan 1.         0.53\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.5075            nan        nan 1.         0.5825\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52739362 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 2\n",
      "n_candidates: 18\n",
      "n_resources: 180\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56666667 0.55              nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.51666667\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.48333333        nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.68333333        nan        nan\n",
      " 0.56666667 0.68333333        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.63333333        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.61666667        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.58939394 0.58787879\n",
      " 0.58939394 0.55151515 0.58787879 0.55151515 0.55151515 0.58939394\n",
      " 0.58787879 0.55151515 0.60757576 0.58939394 0.56969697 0.55151515\n",
      " 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.56969697 0.56969697 0.55151515 0.55151515 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.55151515 0.56969697 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.60606061 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.60757576 0.58939394 0.60757576 0.60757576 0.71507937 0.72079365\n",
      " 0.68650794 0.68650794 0.68650794 0.68095238 0.68095238 0.68095238\n",
      " 0.68095238 0.66380952 0.45396825 0.66380952 0.66380952 0.66380952\n",
      " 0.66380952 0.66380952 0.66380952 0.66380952]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         0.545             nan        nan 1.         0.6325\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.52              nan        nan 1.         0.53\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.5075            nan        nan 1.         0.5825\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52739362 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362\n",
      " 0.99582362 0.99443473 0.72169775 0.99582362 0.99443473 0.99582362\n",
      " 0.99582362 0.99582362 0.99443473 0.99443473]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 540\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56666667 0.55              nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.51666667\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.48333333        nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.68333333        nan        nan\n",
      " 0.56666667 0.68333333        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.63333333        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.61666667        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.58939394 0.58787879\n",
      " 0.58939394 0.55151515 0.58787879 0.55151515 0.55151515 0.58939394\n",
      " 0.58787879 0.55151515 0.60757576 0.58939394 0.56969697 0.55151515\n",
      " 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.56969697 0.56969697 0.55151515 0.55151515 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.55151515 0.56969697 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.60606061 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.60757576 0.58939394 0.60757576 0.60757576 0.71507937 0.72079365\n",
      " 0.68650794 0.68650794 0.68650794 0.68095238 0.68095238 0.68095238\n",
      " 0.68095238 0.66380952 0.45396825 0.66380952 0.66380952 0.66380952\n",
      " 0.66380952 0.66380952 0.66380952 0.66380952 0.72952579 0.73322949\n",
      " 0.73322949 0.73322949 0.7556594  0.75752856]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         0.545             nan        nan 1.         0.6325\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.52              nan        nan 1.         0.53\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.5075            nan        nan 1.         0.5825\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52739362 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362\n",
      " 0.99582362 0.99443473 0.72169775 0.99582362 0.99443473 0.99582362\n",
      " 0.99582362 0.99582362 0.99443473 0.99443473 0.96201341 0.96571926\n",
      " 0.96571926 0.96571926 0.99814707 0.99814707]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 1620\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.56666667 0.55              nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.51666667\n",
      "        nan        nan 0.56666667 0.45              nan        nan\n",
      " 0.56666667 0.48333333        nan        nan 0.56666667 0.48333333\n",
      "        nan        nan 0.56666667 0.68333333        nan        nan\n",
      " 0.56666667 0.68333333        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.63333333        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.56666667 0.61666667\n",
      "        nan        nan 0.56666667 0.61666667        nan        nan\n",
      " 0.56666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.61666667 0.61666667\n",
      "        nan        nan 0.61666667 0.61666667        nan        nan\n",
      " 0.61666667 0.61666667        nan        nan 0.58939394 0.58787879\n",
      " 0.58939394 0.55151515 0.58787879 0.55151515 0.55151515 0.58939394\n",
      " 0.58787879 0.55151515 0.60757576 0.58939394 0.56969697 0.55151515\n",
      " 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.56969697 0.56969697 0.55151515 0.55151515 0.56969697\n",
      " 0.56969697 0.56969697 0.56969697 0.55151515 0.56969697 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.60606061 0.55151515\n",
      " 0.55151515 0.60757576 0.55151515 0.55151515 0.55151515 0.55151515\n",
      " 0.60757576 0.58939394 0.60757576 0.60757576 0.71507937 0.72079365\n",
      " 0.68650794 0.68650794 0.68650794 0.68095238 0.68095238 0.68095238\n",
      " 0.68095238 0.66380952 0.45396825 0.66380952 0.66380952 0.66380952\n",
      " 0.66380952 0.66380952 0.66380952 0.66380952 0.72952579 0.73322949\n",
      " 0.73322949 0.73322949 0.7556594  0.75752856 0.77230631 0.77106792]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the train scores are non-finite: [1.         0.545             nan        nan 1.         0.6325\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.52              nan        nan 1.         0.53\n",
      "        nan        nan 1.         0.48              nan        nan\n",
      " 1.         0.5075            nan        nan 1.         0.5825\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      "        nan        nan 1.         1.                nan        nan\n",
      " 1.         1.                nan        nan 1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         0.52739362 1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362 0.99582362\n",
      " 0.99582362 0.99443473 0.72169775 0.99582362 0.99443473 0.99582362\n",
      " 0.99582362 0.99582362 0.99443473 0.99443473 0.96201341 0.96571926\n",
      " 0.96571926 0.96571926 0.99814707 0.99814707 0.98425747 0.98441179]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 1000, 'C': np.float64(2.782559402207126)}\n",
      "Validation Accuracy: 0.8713\n",
      "Validation F1 Score: 0.8714\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88     39216\n",
      "           1       0.86      0.87      0.87     35770\n",
      "\n",
      "    accuracy                           0.87     74986\n",
      "   macro avg       0.87      0.87      0.87     74986\n",
      "weighted avg       0.87      0.87      0.87     74986\n",
      "\n",
      "Test Accuracy: 0.5241\n",
      "Test F1 Score: 0.5259\n"
     ]
    }
   ],
   "source": [
    "## noget kodeværk her\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv', usecols=['stemmed_tokens', 'type'])\n",
    "validation_data = pd.read_csv('validation_data.csv', usecols=['stemmed_tokens', 'type'])\n",
    "test_data = pd.read_csv('liar_test.csv', usecols=['stemmed_tokens', 'label'])\n",
    "\n",
    "X_train = train_data['stemmed_tokens']\n",
    "y_train = train_data['type']\n",
    "X_val = validation_data['stemmed_tokens']\n",
    "y_val = validation_data['type']\n",
    "X_test = test_data['stemmed_tokens'] \n",
    "y_test = test_data['label']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)  # Fixed typo\n",
    "\n",
    "X_train_dense = X_train_tfidf.toarray() if hasattr(X_train_tfidf, \"toarray\") else X_train_tfidf\n",
    "X_val_dense = X_val_tfidf.toarray() if hasattr(X_val_tfidf, \"toarray\") else X_val_tfidf\n",
    "X_test_dense = X_test_tfidf.toarray() if hasattr(X_test_tfidf, \"toarray\") else X_test_tfidf\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 500, 1000, 5000]\n",
    "}\n",
    "\n",
    "search = HalvingRandomSearchCV(\n",
    "    estimator=LogisticRegression(class_weight='balanced'),\n",
    "    param_distributions=param_grid,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search.fit(X_train_dense, y_train)\n",
    "\n",
    "y_val_pred = search.predict(X_val_dense)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "print(\"Best Parameters:\", search.best_params_)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "print(\"Validation Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "\n",
    "y_test_pred = search.predict(X_test_dense)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[246 203]\n",
      " [173 168]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Reliable (0)', 'Fake (1)'],\n",
    "            yticklabels=['Reliable (0)', 'Fake (1)'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix – LIAR Set (Advanced LR)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
